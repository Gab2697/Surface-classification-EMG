{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMG_ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYZKTy7ABaqQkHB2PQ4LWg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gab2697/Surface-classification-EMG/blob/main/EMG_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o8F6dg5-ikYS"
      },
      "outputs": [],
      "source": [
        "#import\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from keras import layers \n",
        "from keras import models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3rgrkCmintv",
        "outputId": "290800c2-9dad-468b-fa5c-0f0cdce979fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def open_pickle(path_pickle):\n",
        "    f = open(path_pickle, 'rb')\n",
        "    T = pickle.load(f)\n",
        "    f.close()\n",
        "    return T\n",
        "\n",
        "def subject_wise_split(Participant,subject_wise,split=0.10,seed=42):\n",
        "    np.random.seed(seed)\n",
        "    if subject_wise:\n",
        "        UniqParti=np.unique(Participant)\n",
        "        num=np.round(UniqParti.shape[0]*split).astype('int64')\n",
        "        np.random.shuffle(UniqParti)\n",
        "        extract=UniqParti[0:num]\n",
        "        test_index=np.array([],dtype='int64')\n",
        "        for j in extract:\n",
        "            test_index=np.append(test_index,np.where(Participant==j)[0])\n",
        "        train_index=np.delete(np.arange(len(Participant)),test_index)\n",
        "        np.random.shuffle(test_index)\n",
        "        np.random.shuffle(train_index)\n",
        "\n",
        "    else:\n",
        "        I=np.arange(len(Participant)).astype('int64')\n",
        "        np.random.shuffle(I)\n",
        "        num=np.round(Participant.shape[0]*split).astype('int64')\n",
        "        test_index=I[0:num]\n",
        "        train_index=I[num:]\n",
        "        extract=np.unique(Participant[test_index])\n",
        "    return train_index,test_index,extract\n",
        "\n",
        "def make_model_1D(input_size,filter_numb1,filter_numb2,filter_numb3,kernel_size,pool_size,opt):\n",
        "    #Instantiating convnet\n",
        "    model = models.Sequential()\n",
        "    #filter size: 32, kenel of 3, input shape without the batch_size (one trial), padding= with zero padding\n",
        "    model.add(layers.Conv1D(filter_numb1, kernel_size, kernel_regularizer=regularizers.l2(0.001),activation='relu', input_shape=(input_size),padding='same')) \n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.MaxPooling1D(pool_size))\n",
        "    model.add(layers.Conv1D(filter_numb2, kernel_size, kernel_regularizer=regularizers.l2(0.001),activation='relu',padding='same'))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    #Adding a classifier on top of the convnet\n",
        "    model.add(layers.Flatten()) \n",
        "    model.add(layers.Dense(filter_numb3, activation='relu')) \n",
        "    model.add(layers.Dense(1, activation='sigmoid')) \n",
        "    # model.summary()\n",
        "\n",
        "    model.compile(optimizer = opt, loss='binary_crossentropy', metrics=['accuracy']) \n",
        "    return model "
      ],
      "metadata": {
        "id": "Sk2dhAXtipjg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load pickle file\n",
        "Ndata=open_pickle('/content/drive/MyDrive/Gab/Variables_saved/All_emg/data.pkl') "
      ],
      "metadata": {
        "id": "TC2o1lXQlMSO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Condition and surface number instead of array\n",
        "for i in range(Ndata['Conditions'].shape[0]):\n",
        "    Ndata['Conditions'][i]=Ndata['Conditions'][i][0]\n",
        "    Ndata['Subject'][i]=Ndata['Subject'][i][0]"
      ],
      "metadata": {
        "id": "kGrGhNtPxf3L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Surface=Ndata['Conditions']\n",
        "Participant=Ndata['Subject']\n",
        "del Ndata['Conditions']\n",
        "del Ndata['Subject']"
      ],
      "metadata": {
        "id": "rH8HMK-wUHBU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create dictionary with numpy array\n",
        "data={}\n",
        "\n",
        "for i in Ndata.keys():\n",
        "  data[i]=np.zeros([5256,7704])\n",
        "  for j in range(Ndata[i].shape[0]):\n",
        "    data[i][j,:]=Ndata[i][j].transpose()[:,0]"
      ],
      "metadata": {
        "id": "DvUvagyJIURq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata={}\n",
        "for i in data.keys():\n",
        "    for j in range(8):\n",
        "        newdata[f'{i}_{j}']=data[i][:,j*963:963+(j*963)]"
      ],
      "metadata": {
        "id": "GM4mlecmTou0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_index,test_index,extract=subject_wise_split(np.array(Participant),split=0.15,subject_wise=False,seed=5)\n",
        "train_index,test_index=train_index.astype('int64'),test_index.astype('int64')        "
      ],
      "metadata": {
        "id": "o-ZMNGwiT4J1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "2zYDvRpfU0WA",
        "outputId": "ff93af94-4d3f-4809-e916-c0d5b988d377"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ba11e752bd4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnnData={'X_train':{},'X_test':{},'y_train':{},'y_test':{}}\n",
        "\n",
        "for i in newdata.keys():\n",
        "  Data['X_train'][f'{i}']=newdata[train_index]\n",
        "  Data['X_test'][f'{i}']=newdata[test_index]\n",
        "  Data['y_train'][f'{i}']=Surface[train_index]\n",
        "  Data['y_test'][f'{i}']=Surface[test_index]"
      ],
      "metadata": {
        "id": "cyIKJjNLT_6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Data['X_train'].keys():\n",
        "    X_train.append(Data['X_train'][i])\n",
        "    X_test.append(Data['X_test'][i])"
      ],
      "metadata": {
        "id": "2qU8EP_ZVuhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)"
      ],
      "metadata": {
        "id": "Eh9iiO40V9ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=X_train.reshape(X_train.shape[1],X_train.shape[0],1)\n",
        "x_test=X_test.reshape(X_test.shape[1],X_test.shape[0],1)"
      ],
      "metadata": {
        "id": "dTAUOvh7WAyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=make_model_1D(x_train.shape[0],32,64,64,3,2,SGD(lr=0.01))\n",
        "history= model.fit(x_train,y_train, epochs=10, batch_size=100,validation_data=(x_valid,y_valid))"
      ],
      "metadata": {
        "id": "GqwWTkXTWJFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ESy32XZtdoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other stuff I tested"
      ],
      "metadata": {
        "id": "vq2XyKRJtbEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing gravel for now\n",
        "Ndata_no_gravel=Ndata[Ndata['Conditions'] != 'gravel ']\n",
        "print('shape of data with the gravel surface:',Ndata.shape)\n",
        "print('shape of data without the gravel surface:',pd.DataFrame(Ndata_no_gravel).shape)\n",
        "np.unique(Ndata_no_gravel['Conditions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6xj5SVJjy2h",
        "outputId": "a2275181-52bb-4bb5-c7d4-533cdc31a9bf"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data with the gravel surface: (5256, 6)\n",
            "shape of data without the gravel surface: (5216, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['asphalt', 'grass  '], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scikit-learn k-fold cross-validation\n",
        "from numpy import array\n",
        "\n",
        "# data sample\n",
        "data = Ndata_no_gravel\n",
        "# split into train test sets\n",
        "n = len(pd.unique(Ndata_no_gravel['Subject'])) # number of participants\n",
        "n_train= round(0.8*n) # number of participants for trianing\n",
        "print('number of participants for the training set:', n_train)\n",
        "n_test= n-n_train #number of participant for testing\n",
        "#index of the last participant for trianing\n",
        "n=Ndata_no_gravel.loc[Ndata_no_gravel['Subject'] == 'P28'].index\n",
        "Ndata_train= Ndata_no_gravel.iloc[:n[-1],:] #select training set\n",
        "Ndata_test= Ndata_no_gravel.iloc[n[-1]:,:] #select testing set\n",
        "print('test set shape:', Ndata_test.shape)\n",
        "\n",
        "#validation set\n",
        "n_train2=round(n_train*0.8)\n",
        "print('number of participants for the final training set:', n_train2)\n",
        "n2=Ndata_train.loc[Ndata_train['Subject'] == 'P22'].index\n",
        "Ndata_train2= Ndata_train.iloc[:n2[-1],:] #select final training set\n",
        "Ndata_valid= Ndata_train.iloc[n2[-1]:,:] #select validation testing set\n",
        "print('valid set shape:', Ndata_valid.shape, 'training set shape:', Ndata_train2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77YMARrAoyI",
        "outputId": "27a45abd-7f1f-4ae0-afa9-14483eb68a4c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of participants for the training set: 28\n",
            "test set shape: (1859, 6)\n",
            "number of participants for the final training set: 22\n",
            "valid set shape: (965, 6) training set shape: (2392, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seperate x data and it's label\n",
        "\n",
        "Surface_train=Ndata_train2['Conditions']\n",
        "Participant_train=Ndata_train2['Subject']\n",
        "del Ndata_train2['Conditions']\n",
        "del Ndata_train2['Subject']\n",
        "\n",
        "Surface_valid=Ndata_valid['Conditions']\n",
        "Participant_valid=Ndata_valid['Subject']\n",
        "del Ndata_valid['Conditions']\n",
        "del Ndata_valid['Subject']\n",
        "\n",
        "# TA=Ndata['Trignosensor1TAEMG1Volts']\n",
        "# Gastroc=Ndata['Trignosensor2GastrocEMG2Volts']\n",
        "# RF=Ndata['Trignosensor3RFEMG3Volts']\n",
        "# BF=Ndata['Trignosensor4BFEMG4Volts']"
      ],
      "metadata": {
        "id": "43nkSMu-fdF3"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=Ndata_train2\n",
        "y_train=Surface_train\n",
        "x_valid=Ndata_valid\n",
        "y_valid=Surface_valid"
      ],
      "metadata": {
        "id": "RTi2vUHqh4XF"
      },
      "execution_count": 120,
      "outputs": []
    }
  ]
}