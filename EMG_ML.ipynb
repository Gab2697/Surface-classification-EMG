{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMG_ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXog3wzQ0TOzAy9vsOLc3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gab2697/Surface-classification-EMG/blob/main/EMG_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8F6dg5-ikYS"
      },
      "outputs": [],
      "source": [
        "#import\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from keras import layers \n",
        "from keras import models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3rgrkCmintv",
        "outputId": "4a12880c-7ed0-47ee-92d5-73bbf9ef18f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def open_pickle(path_pickle):\n",
        "    f = open(path_pickle, 'rb')\n",
        "    T = pickle.load(f)\n",
        "    f.close()\n",
        "    return T\n",
        "\n",
        "def subject_wise_split(Participant,subject_wise,split=0.10,seed=42):\n",
        "    np.random.seed(seed)\n",
        "    if subject_wise:\n",
        "        UniqParti=np.unique(Participant)\n",
        "        num=np.round(UniqParti.shape[0]*split).astype('int64')\n",
        "        np.random.shuffle(UniqParti)\n",
        "        extract=UniqParti[0:num]\n",
        "        test_index=np.array([],dtype='int64')\n",
        "        for j in extract:\n",
        "            test_index=np.append(test_index,np.where(Participant==j)[0])\n",
        "        train_index=np.delete(np.arange(len(Participant)),test_index)\n",
        "        np.random.shuffle(test_index)\n",
        "        np.random.shuffle(train_index)\n",
        "\n",
        "    else:\n",
        "        I=np.arange(len(Participant)).astype('int64')\n",
        "        np.random.shuffle(I)\n",
        "        num=np.round(Participant.shape[0]*split).astype('int64')\n",
        "        test_index=I[0:num]\n",
        "        train_index=I[num:]\n",
        "        extract=np.unique(Participant[test_index])\n",
        "    return train_index,test_index,extract\n",
        "\n",
        "def one_hot(y):\n",
        "    uniq=np.unique(y)\n",
        "    y_hot=np.zeros([y.shape[0],uniq.shape[0]])\n",
        "    for i in range(len(uniq)):\n",
        "        index=np.where(y==uniq[i])[0]\n",
        "        y_hot[index,i]=1\n",
        "    surface_name=uniq\n",
        "    return y_hot\n",
        "\n",
        "def CNN_test(input_shape,output_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def ANN(hid_layers,model,output,input_shape,activation_hid='relu'):\n",
        "  ann = tf.keras.models.Sequential()\n",
        "  ann.add(tf.keras.Input(shape=input_shape))\n",
        "  for l in hid_layers:\n",
        "    ann.add(tf.keras.layers.Dense(units=l,activation=activation_hid))\n",
        "    if model=='classification':\n",
        "      ann.add(tf.keras.layers.Dense(units=output,activation='softmax'))\n",
        "      ann.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    return ann"
      ],
      "metadata": {
        "id": "Sk2dhAXtipjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load pickle file\n",
        "Ndata=open_pickle('/content/drive/MyDrive/Gab/Variables_saved/All_emg/data_good.pkl') "
      ],
      "metadata": {
        "id": "TC2o1lXQlMSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape into 3D arrays \n",
        "import math\n",
        "data=np.zeros([Ndata.shape[0],7704,4])\n",
        "Parameters=Ndata.keys()\n",
        "for i in range(len(Parameters)-2):\n",
        "  for j in range(len(Ndata[Parameters[i]])):\n",
        "    data[j,:,i]=math.log(Ndata[Parameters[i]].to_numpy()[j].reshape(7704))\n",
        "\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "E-I_3uPSWcH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "  x=math.log(data[i])"
      ],
      "metadata": {
        "id": "FuA5WtuQTi_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Participant= Ndata['Subject']\n",
        "Surface= Ndata['Conditions']"
      ],
      "metadata": {
        "id": "RC3Iy4xVktGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seperate train and test set\n",
        "train_index,test_index,extract=subject_wise_split(np.array(Participant),split=0.15,subject_wise=False,seed=5)\n",
        "train_index,test_index=train_index.astype('int64'),test_index.astype('int64')   \n",
        "\n",
        "X_train=data[train_index]\n",
        "X_test=data[test_index]\n",
        "y_train=Surface[train_index]\n",
        "y_test=Surface[test_index]"
      ],
      "metadata": {
        "id": "ud8UXeVKfWra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.to_numpy()\n",
        "y_test=y_test.to_numpy()"
      ],
      "metadata": {
        "id": "N1lcYrYSGINg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding for label\n",
        "X_train=np.asarray(X_train).astype(np.float32) \n",
        "y_train=one_hot(y_train)\n",
        "X_test=np.asarray(X_test).astype(np.float32) \n",
        "y_test=one_hot(y_test)"
      ],
      "metadata": {
        "id": "vUhc4QVazuEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=CNN_test(X_train.shape[1:],2)"
      ],
      "metadata": {
        "id": "fqekXq1GNpA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history= model.fit(X_train,y_train, epochs=10, batch_size=200,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "5Vd_3Mg-mr0B",
        "outputId": "578ff9eb-ac7f-49ae-8f90-59d08fee5891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 147s 6s/step - loss: 8096.3428 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4834\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 143s 6s/step - loss: 0.6927 - accuracy: 0.4995 - val_loss: 0.6934 - val_accuracy: 0.4834\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 143s 6s/step - loss: 0.6927 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.4834\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 138s 6s/step - loss: 0.6927 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.4834\n",
            "Epoch 5/10\n",
            "14/23 [=================>............] - ETA: 53s - loss: 0.6924 - accuracy: 0.5018"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b3eebd2ccf3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "Ndara_grass=Ndata[Ndata['Conditions'] == 'grass ']\n",
        "Ndara_asphalt=Ndata[Ndata['Conditions'] == 'asphalt ']\n",
        "rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=Ndara_grass)\n",
        "rvs2 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=Ndara_asphalt)\n",
        "stats.ttest_ind(rvs1, rvs2)"
      ],
      "metadata": {
        "id": "vnLfxL8f5gki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "other"
      ],
      "metadata": {
        "id": "oCSGuBBEfXBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Condition and surface number instead of array\n",
        "for i in range(Ndata['Conditions'].shape[0]):\n",
        "    Ndata['Conditions'][i]=Ndata['Conditions'][i][0]\n",
        "    Ndata['Subject'][i]=Ndata['Subject'][i][0]"
      ],
      "metadata": {
        "id": "kGrGhNtPxf3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Surface=Ndata['Conditions']\n",
        "Participant=Ndata['Subject']\n",
        "del Ndata['Conditions']\n",
        "del Ndata['Subject']"
      ],
      "metadata": {
        "id": "rH8HMK-wUHBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create dictionary with numpy array\n",
        "data={}\n",
        "\n",
        "for i in Ndata.keys():\n",
        "  data[i]=np.zeros([5256,7704])\n",
        "  for j in range(Ndata[i].shape[0]):\n",
        "    data[i][j,:]=Ndata[i][j].transpose()[:,0]"
      ],
      "metadata": {
        "id": "DvUvagyJIURq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata={}\n",
        "for i in data.keys():\n",
        "    for j in range(8):\n",
        "        newdata[f'{i}_{j}']=data[i][:,j*963:963+(j*963)]"
      ],
      "metadata": {
        "id": "GM4mlecmTou0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_index,test_index,extract=subject_wise_split(np.array(Participant),split=0.15,subject_wise=False,seed=5)\n",
        "train_index,test_index=train_index.astype('int64'),test_index.astype('int64')        "
      ],
      "metadata": {
        "id": "o-ZMNGwiT4J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnData={'X_train':{},'X_test':{},'y_train':{},'y_test':{}}\n",
        "\n",
        "for i in newdata.keys():\n",
        "  Data['X_train'][f'{i}']=newdata[train_index]\n",
        "  Data['X_test'][f'{i}']=newdata[test_index]\n",
        "  Data['y_train'][f'{i}']=Surface[train_index]\n",
        "  Data['y_test'][f'{i}']=Surface[test_index]"
      ],
      "metadata": {
        "id": "cyIKJjNLT_6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Data['X_train'].keys():\n",
        "    X_train.append(Data['X_train'][i])\n",
        "    X_test.append(Data['X_test'][i])"
      ],
      "metadata": {
        "id": "2qU8EP_ZVuhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)"
      ],
      "metadata": {
        "id": "Eh9iiO40V9ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=X_train.reshape(X_train.shape[1],X_train.shape[0],1)\n",
        "x_test=X_test.reshape(X_test.shape[1],X_test.shape[0],1)"
      ],
      "metadata": {
        "id": "dTAUOvh7WAyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=make_model_1D(x_train.shape[0],32,64,64,3,2,SGD(lr=0.01))\n",
        "history= model.fit(x_train,y_train, epochs=10, batch_size=100,validation_data=(x_valid,y_valid))"
      ],
      "metadata": {
        "id": "GqwWTkXTWJFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ESy32XZtdoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other stuff I tested"
      ],
      "metadata": {
        "id": "vq2XyKRJtbEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing gravel for now\n",
        "Ndata_no_gravel=Ndata[Ndata['Conditions'] != 'gravel ']\n",
        "print('shape of data with the gravel surface:',Ndata.shape)\n",
        "print('shape of data without the gravel surface:',pd.DataFrame(Ndata_no_gravel).shape)\n",
        "np.unique(Ndata_no_gravel['Conditions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6xj5SVJjy2h",
        "outputId": "a2275181-52bb-4bb5-c7d4-533cdc31a9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data with the gravel surface: (5256, 6)\n",
            "shape of data without the gravel surface: (5216, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['asphalt', 'grass  '], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scikit-learn k-fold cross-validation\n",
        "from numpy import array\n",
        "\n",
        "# data sample\n",
        "data = Ndata_no_gravel\n",
        "# split into train test sets\n",
        "n = len(pd.unique(Ndata_no_gravel['Subject'])) # number of participants\n",
        "n_train= round(0.8*n) # number of participants for trianing\n",
        "print('number of participants for the training set:', n_train)\n",
        "n_test= n-n_train #number of participant for testing\n",
        "#index of the last participant for trianing\n",
        "n=Ndata_no_gravel.loc[Ndata_no_gravel['Subject'] == 'P28'].index\n",
        "Ndata_train= Ndata_no_gravel.iloc[:n[-1],:] #select training set\n",
        "Ndata_test= Ndata_no_gravel.iloc[n[-1]:,:] #select testing set\n",
        "print('test set shape:', Ndata_test.shape)\n",
        "\n",
        "#validation set\n",
        "n_train2=round(n_train*0.8)\n",
        "print('number of participants for the final training set:', n_train2)\n",
        "n2=Ndata_train.loc[Ndata_train['Subject'] == 'P22'].index\n",
        "Ndata_train2= Ndata_train.iloc[:n2[-1],:] #select final training set\n",
        "Ndata_valid= Ndata_train.iloc[n2[-1]:,:] #select validation testing set\n",
        "print('valid set shape:', Ndata_valid.shape, 'training set shape:', Ndata_train2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77YMARrAoyI",
        "outputId": "27a45abd-7f1f-4ae0-afa9-14483eb68a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of participants for the training set: 28\n",
            "test set shape: (1859, 6)\n",
            "number of participants for the final training set: 22\n",
            "valid set shape: (965, 6) training set shape: (2392, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seperate x data and it's label\n",
        "\n",
        "Surface_train=Ndata_train2['Conditions']\n",
        "Participant_train=Ndata_train2['Subject']\n",
        "del Ndata_train2['Conditions']\n",
        "del Ndata_train2['Subject']\n",
        "\n",
        "Surface_valid=Ndata_valid['Conditions']\n",
        "Participant_valid=Ndata_valid['Subject']\n",
        "del Ndata_valid['Conditions']\n",
        "del Ndata_valid['Subject']\n",
        "\n",
        "# TA=Ndata['Trignosensor1TAEMG1Volts']\n",
        "# Gastroc=Ndata['Trignosensor2GastrocEMG2Volts']\n",
        "# RF=Ndata['Trignosensor3RFEMG3Volts']\n",
        "# BF=Ndata['Trignosensor4BFEMG4Volts']"
      ],
      "metadata": {
        "id": "43nkSMu-fdF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=Ndata_train2\n",
        "y_train=Surface_train\n",
        "x_valid=Ndata_valid\n",
        "y_valid=Surface_valid"
      ],
      "metadata": {
        "id": "RTi2vUHqh4XF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}